{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e9ed770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSastrawi\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mStemmer\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mStemmerFactory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StemmerFactory\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee8440b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nama Akun</th>\n",
       "      <th>Komentar</th>\n",
       "      <th>Sumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@azzahrasyamilarahmat5028</td>\n",
       "      <td>11/100 Is Real...</td>\n",
       "      <td>Narasi Newsroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@faritrohman3969</td>\n",
       "      <td>Saya kecewa cuma gara gara beberapa anak kelua...</td>\n",
       "      <td>Narasi Newsroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@moradepadli5676</td>\n",
       "      <td>Prabowo aneh</td>\n",
       "      <td>Narasi Newsroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@anggaviali1188</td>\n",
       "      <td>Nonton tanpa baca komen itu lebih baik</td>\n",
       "      <td>Narasi Newsroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@derikoswaranda3500</td>\n",
       "      <td>woyyy mana ini?? ko komenan ga ada yg pro pa w...</td>\n",
       "      <td>Narasi Newsroom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Nama Akun  \\\n",
       "0  @azzahrasyamilarahmat5028   \n",
       "1           @faritrohman3969   \n",
       "2           @moradepadli5676   \n",
       "3            @anggaviali1188   \n",
       "4        @derikoswaranda3500   \n",
       "\n",
       "                                            Komentar           Sumber  \n",
       "0                                  11/100 Is Real...  Narasi Newsroom  \n",
       "1  Saya kecewa cuma gara gara beberapa anak kelua...  Narasi Newsroom  \n",
       "2                                       Prabowo aneh  Narasi Newsroom  \n",
       "3             Nonton tanpa baca komen itu lebih baik  Narasi Newsroom  \n",
       "4  woyyy mana ini?? ko komenan ga ada yg pro pa w...  Narasi Newsroom  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('prabowo_menjawab.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7ab6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15020 entries, 0 to 15019\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Nama Akun  15017 non-null  object\n",
      " 1   Komentar   15016 non-null  object\n",
      " 2   Sumber     15020 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 352.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1fe91",
   "metadata": {},
   "source": [
    "Normalisasi + Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a0871ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "# Load kamus slang eksternal (misalnya dari nasalsabila/kamus-alay)\n",
    "slang_df = pd.read_csv('https://raw.githubusercontent.com/nasalsabila/kamus-alay/refs/heads/master/colloquial-indonesian-lexicon.csv')  # Unduh dari GitHub atau buat sendiri\n",
    "slang_dict = dict(zip(slang_df['slang'], slang_df['formal']))\n",
    "\n",
    "def bersihkan_komentar(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Hapus URL\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    # Hapus mention & hashtag\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Hapus angka & simbol non-alphabetic\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenisasi\n",
    "    words = text.split()\n",
    "    # Ganti kata slang\n",
    "    words = [slang_dict.get(word, word) for word in words]\n",
    "    # Stemming\n",
    "    stemmed = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Komentar_Bersih'] = df['Komentar'].astype(str).apply(bersihkan_komentar)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6faa5292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load model IndoBERT sentiment\u001b[39;00m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mw11wo/indonesian-sentiment-twitter\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m tokenizer = \u001b[43mAutoTokenizer\u001b[49m.from_pretrained(model_name)\n\u001b[32m      4\u001b[39m model = AutoModelForSequenceClassification.from_pretrained(model_name)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Deteksi sentimen\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load model IndoBERT sentiment\n",
    "model_name = \"w11wo/indonesian-sentiment-twitter\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Deteksi sentimen\n",
    "labels = ['negative', 'neutral', 'positive']\n",
    "hasil_prediksi = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProyekNLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
